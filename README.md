# üß† TOXIC PROMPT Classification ‚Äì GENAI Assessment

This project focuses on building a transformer-based classification system to detect **toxic prompts** in text using Natural Language Processing (NLP) techniques. It was built as part of a GENAI Assessment to showcase the application of responsible AI.

---

## üìå Objective

To fine-tune a transformer model that can accurately classify prompts as **toxic** or **non-toxic**, enabling effective **prompt guardrails** in AI systems and minimizing the spread of harmful content.

---

## ‚öôÔ∏è Environment Setup

Ensure the following tools and libraries are installed in your Python environment:

### 1. Clone the Repository

```bash
git clone https://github.com/Prathama-1/TOXIC-PROMPT-Classification.git
cd TOXIC-PROMPT-Classification

